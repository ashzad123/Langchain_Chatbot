# Langchain Chatbot using Llama2

This project is a chatbot application built using the LangChain framework and the Llama2 model provided by Ollama. The app uses Streamlit to create an interactive user interface where users can input queries and receive responses generated by the Llama2 language model.

## Features
- **Streamlit Interface**: An easy-to-use web interface for users to interact with the chatbot.
- **Llama2 Model**: Uses the Llama2 model provided by Ollama for natural language understanding.
- **LangSmith Tracing**: Tracks and logs interactions for further analysis using LangChain’s tracing tool.
- **Customizable Prompts**: Includes a customizable system message for tailoring responses to different user contexts.

## Setup Instructions

### Prerequisites
Ensure you have the following installed on your machine:
- Python 3.8+
- Streamlit
- LangChain
- Ollama
- dotenv (for environment variable management)

### Installation
1. **Clone the Repository**:
    ```bash
    git clone https://github.com/ashzad123/Langchain_Chatbot.git
    cd langchain_Chatbot
    ```

2. **Install Dependencies**:
    Use `pip` to install the required packages:
    ```bash
    pip install -r requirements.txt
    ```

3. **Environment Variables**:
    Create a `.env` file in the project root to store your LangChain API key:
    ```bash
    touch .env
    ```

4. **Add your LangChain API Key**:
    Inside your `.env` file, add the following:
    ```bash
    LANGCHAIN_API_KEY=your-langchain-api-key
    ```

### Running the App
1. To run the Streamlit app, use the following command:
    ```bash
    streamlit run app.py
    ```

2. Open your browser and go to `http://localhost:8501/` to interact with the chatbot.

## Environment Variables
This project uses environment variables to manage API keys securely. You need to define the following variables in your `.env` file:

- **LANGCHAIN_API_KEY**: Your API key for LangChain.


# How It Works
1. **User Input**: The user types a question into the input field provided by Streamlit.
2. **Prompt Creation**: A prompt template is generated using the `ChatPromptTemplate` class from LangChain, which includes a system message and the user’s question.
3. **Model Invocation**: The prompt is passed to the Llama2 model through the `Ollama` integration, and the model generates a response.
4. **Response Parsing**: The response is parsed using `StrOutputParser` and displayed back to the user in the Streamlit interface.

## How It Works
1. **User Input**: The user types a question into the input field provided by Streamlit.
2. **Prompt Creation**: A prompt template is generated using the `ChatPromptTemplate` class from LangChain, which includes a system message and the user’s question.
3. **Model Invocation**: The prompt is passed to the Llama2 model through the `Ollama` integration, and the model generates a response.
4. **Response Parsing**: The response is parsed using `StrOutputParser` and displayed back to the user in the Streamlit interface.

## Documentation Links
- [LangChain Documentation](https://docs.langchain.com)
- [Ollama Documentation](https://www.ollama.com/docs)
- [Streamlit Documentation](https://docs.streamlit.io)
- [LangSmith Tracing Documentation](https://docs.smith.langchain.com)

## Technologies Used
- **LangChain**: A framework for building applications with language models.
- **Llama2**: A state-of-the-art language model provided by Ollama.
- **Streamlit**: A Python library used to build interactive web applications.
- **dotenv**: For managing environment variables.
- **LangSmith**: For tracing and logging interactions in LangChain.


## Contributing
If you'd like to contribute to this project, feel free to fork the repository, make changes, and submit a pull request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the repository.
2. Create a new branch for your feature (`git checkout -b feature/YourFeature`).
3. Commit your changes (`git commit -m 'Add YourFeature'`).
4. Push to the branch (`git push origin feature/YourFeature`).
5. Open a pull request.