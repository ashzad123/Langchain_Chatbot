# Langchain Chatbot using Llama2

This project is a chatbot application built using the LangChain framework and the Llama2 model provided by Ollama. The app uses Streamlit to create an interactive user interface where users can input queries and receive responses generated by the Llama2 language model.

## Features
- **Streamlit Interface**: An easy-to-use web interface for users to interact with the chatbot.
- **Llama2 Model**: Uses the Llama2 model provided by Ollama for natural language understanding.
- **LangSmith Tracing**: Tracks and logs interactions for further analysis using LangChain’s tracing tool.
- **Customizable Prompts**: Includes a customizable system message for tailoring responses to different user contexts.

## Setup Instructions

### Prerequisites
Ensure you have the following installed on your machine:
- Python 3.8+
- Streamlit
- LangChain
- Ollama
- dotenv (for environment variable management)

### Installation
1. **Clone the Repository**:
    ```bash
    git clone https://github.com/ashzad123/Langchain_Chatbot.git
    cd langchain_Chatbot
    ```

2. **Install Dependencies**:
    Use `pip` to install the required packages:
    ```bash
    pip install -r requirements.txt
    ```

3. **Environment Variables**:
    Create a `.env` file in the project root to store your LangChain API key:
    ```bash
    touch .env
    ```

4. **Add your LangChain API Key**:
    Inside your `.env` file, add the following:
    ```bash
    LANGCHAIN_API_KEY=your-langchain-api-key
    ```

### Running the App
1. To run the Streamlit app, use the following command:
    ```bash
    streamlit run app.py
    ```

2. Open your browser and go to `http://localhost:8501/` to interact with the chatbot.

## Environment Variables
This project uses environment variables to manage API keys securely. You need to define the following variables in your `.env` file:

- **LANGCHAIN_API_KEY**: Your API key for LangChain.


# How It Works
1. **User Input**: The user types a question into the input field provided by Streamlit.
2. **Prompt Creation**: A prompt template is generated using the `ChatPromptTemplate` class from LangChain, which includes a system message and the user’s question.
3. **Model Invocation**: The prompt is passed to the Llama2 model through the `Ollama` integration, and the model generates a response.
4. **Response Parsing**: The response is parsed using `StrOutputParser` and displayed back to the user in the Streamlit interface.